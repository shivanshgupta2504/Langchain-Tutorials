{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 1: Defining a TypedDict Schema for Basic Extraction\n",
    "\n",
    "Assume you are working on a Python-only project and need to extract information from movie reviews. You only need Type Hinting, not validation.\n",
    "\n",
    "**Required Steps:**\n",
    "\n",
    "A. Define a class `MovieInfo` inheriting from `TypedDict`.\n",
    "\n",
    "B. Define two attributes: `title` (String) and `rating_out_of_five` (Integer).\n",
    "\n",
    "C. *Conceptual:* If an LLM using this schema accidentally returned the rating as \"4.5 stars\" (a string), would this method prevent the code from running or signal an error at runtime, and why?"
   ],
   "id": "aa9f6e745a5a11da"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-16T13:47:37.934283Z",
     "start_time": "2025-11-16T13:47:36.493424Z"
    }
   },
   "source": [
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T13:48:53.803339Z",
     "start_time": "2025-11-16T13:48:53.788102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MovieInfo(TypedDict):\n",
    "    title: str\n",
    "    rating_out_of_five: int"
   ],
   "id": "fc276d4b43fa0a69",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T13:52:11.447497Z",
     "start_time": "2025-11-16T13:52:09.034416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "structured_model = model.with_structured_output(MovieInfo)\n",
    "\n",
    "prompt = \"\"\"\n",
    "I gave the 4 out of 5 rating for movie named Thunderbolts\n",
    "\"\"\"\n",
    "\n",
    "res = structured_model.invoke(prompt)\n",
    "print(res)\n",
    "\n",
    "# Since there is no type checking here so whatever LLM returns won't be a issue"
   ],
   "id": "4145cc12cc9b5c39",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shivansh Gupta\\OneDrive\\Desktop\\Data Science\\My Data Science\\Langchain-Tutorials\\langchain\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1927: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Thunderbolts', 'rating_out_of_five': 4}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 2: Pydantic Validation and Constraint Enforcement (Pydantic Output Parser)\n",
    "\n",
    "You need to extract technical details about a new CPU. The extracted data must be strictly validated.\n",
    "\n",
    "**Required Steps:**\n",
    "\n",
    "A. Define a Pydantic `BaseModel` called `CPUDetails`.\n",
    "\n",
    "C. Include attributes for `core_count` (Integer) and `base_frequency_ghz` (Float).\n",
    "\n",
    "C. Use the `Field` function to enforce the following constraints on `core_count`: it must be greater than or equal to 4 and less than 12.\n",
    "\n",
    "D. Write the initial setup for the Pydantic Output Parser, including retrieving the necessary `format_instructions`."
   ],
   "id": "b71d8806a76532a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T14:08:53.789245Z",
     "start_time": "2025-11-16T14:08:47.858482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "class CPUDetails(BaseModel):\n",
    "    name: str = Field(description=\"Name of the CPU used in the System\")\n",
    "    core_count: int = Field(description=\"Number of CPU cores\", ge=4, lt=12)\n",
    "    base_frequency_ghz: float = Field(description=\"Base frequency of CPU cores\")\n",
    "\n",
    "model = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=CPUDetails)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"Give me any CPU details being used in any Windows Computer or Laptop\\n {format_inst}\",\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_inst\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | model | parser\n",
    "res = chain.invoke(input={})\n",
    "print(res)"
   ],
   "id": "bb23dfc4ae549bca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Desktop PC' core_count=4 base_frequency_ghz=2.8\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Task 3: Simulating a Two-Step Agent Tool Chain (String Output Parser)\n",
    "\n",
    "An Agent needs to first research a company and then summarize that information into three bullet points. Use a chain flow incorporating the String Output Parser.\n",
    "\n",
    "**Required Steps:**\n",
    "\n",
    "A. Define `prompt_template_research` (`input_variables=[\"company\"]`).\n",
    "\n",
    "B. Define `prompt_template_summary` (`input_variables=[\"research_output\"]`).\n",
    "\n",
    "C. Define the `StringOutputParser`.\n",
    "\n",
    "D. Construct the full chain pipeline (Template $\\rightarrow$ Model $\\rightarrow$ Parser $\\rightarrow$ Template $\\rightarrow$ Model) to complete the task."
   ],
   "id": "20d85321cccf63d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T14:19:59.452192Z",
     "start_time": "2025-11-16T14:19:03.900297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "research_template = PromptTemplate(\n",
    "    template=\"Do a detailed research on {company}\",\n",
    "    input_variables=[\"company\"],\n",
    ")\n",
    "\n",
    "summary_template = PromptTemplate(\n",
    "    template=\"Summarize the following text in 3 bullet points.\\n{text}\",\n",
    "    input_variables=[\"text\"],\n",
    ")\n",
    "\n",
    "chain = research_template | model | parser | summary_template | model | parser\n",
    "res = chain.invoke(input={\"company\": \"Boeing\"})\n",
    "print(res)"
   ],
   "id": "17688944a0818f5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Boeing is a leading aerospace and defense company organized around Commercial Airplanes (CBA), Defense, Space & Security (BDS), and Global Services, with a large backlog, a global footprint, and significant NASA/space program involvement.\n",
      "\n",
      "- It has recovered from the 737 MAX crisis but continues to navigate program delays (notably 777X), supply-chain and quality challenges, and ongoing regulatory/safety scrutiny, while expanding defense/space offerings and services to diversify revenue.\n",
      "\n",
      "- The strategic outlook focuses on ramping high-demand commercial production, expanding defense/space modernization, and growing services and digital solutions, balanced by risks from supply chain volatility, macro conditions, and program execution; ESG considerations and international opportunities are central to strategy.\n",
      "\n",
      "If youâ€™d like a data-driven version with latest figures (revenue, backlog, deliveries, etc.), I can pull the most recent 10-K/quarterly results and summarize them.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Task 4: Structured Output with Pydantic for Review Analysis\n",
    "\n",
    "Using the `with_structured_output` function (assuming an OpenAI model is used), create a system to analyze product reviews.\n",
    "\n",
    "**Required Steps:**\n",
    "\n",
    "A. Define a Pydantic class `ProductReview` containing:\n",
    "- `product_name` (String, required).\n",
    "- `date_of_review` (String, required).\n",
    "- `is_verified_buyer` (Boolean, required).\n",
    "- `sentiment_score` (Integer, must be between 1 and 5).\n",
    "\n",
    "B. Write the Python code to define the LLM to use this schema directly via `with_structured_output`.\n",
    "\n",
    "C. *Conceptual:* Explain what role the system prompt plays behind the scenes when using `with_structured_output` to guide the LLM toward the desired JSON format."
   ],
   "id": "a5d23f904d95e345"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "15597f7478bba1d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
